{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a1f48eb-4373-4b6a-9ecb-1aa73d428026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd89ccc-5d7d-426e-bf8a-33dc39d3146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d107a4-5171-40ea-be83-f9a24dfccff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-to-Index Mapping: {'Cardboard': 0, 'Food Organics': 1, 'Glass': 2, 'Metal': 3, 'Miscellaneous Trash': 4, 'Paper': 5, 'Plastic': 6, 'Textile Trash': 7, 'Vegetation': 8}\n",
      "Training set size: 3326\n",
      "Validation set size: 712\n",
      "Test set size: 714\n"
     ]
    }
   ],
   "source": [
    "# Path to the main directory\n",
    "main_dir = r\"C:\\Users\\User\\Desktop\\Shahla share\\ai\\Project\\real_waste\\realwaste-main/RealWaste\"\n",
    "# Define transformations for data augmentation and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),            # Resize to 256x256\n",
    "    transforms.CenterCrop(224),              # Crop to 224x224\n",
    "    transforms.ToTensor(),                   # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.ImageFolder(root=main_dir, transform=transform)\n",
    "\n",
    "# Print class-to-index mapping\n",
    "print(\"Class-to-Index Mapping:\", dataset.class_to_idx)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "val_size = int(0.15 * len(dataset))   # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining 15% for testing\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check the number of samples in each split\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a6973d-b515-40cc-b336-e5f1ed9629dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet layers (basic blocks)\n",
    "        self.layer1 = self._make_layer(64, 64, 2)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(self._block(in_channels, out_channels, stride))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(self._block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _block(self, in_channels, out_channels, stride=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "resnet18_model = ResNet18(num_classes=9)\n",
    "print(resnet18_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07cec73f-2c84-4ac3-a1f5-02c94feddc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): ReLU(inplace=True)\n",
      "    (22): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = self._make_layers([\n",
    "            64, 64, 'M', \n",
    "            128, 128, 'M', \n",
    "            256, 256, 256, 'M', \n",
    "            512, 512, 512, 'M', \n",
    "            512, 512, 512, 'M'\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [\n",
    "                    nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(x)\n",
    "                ]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "vgg16_model = VGG16(num_classes=9)\n",
    "print(vgg16_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d485ac51-d371-45ea-b898-c4cae1c262b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Create a writer instance\n",
    "writer = SummaryWriter(log_dir='runs/experiment1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c29e8e-3f8d-47cb-b052-b606cb412c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "import torch\n",
    "\n",
    "def evaluate_model_with_metrics(model, data_loader, device, num_classes):\n",
    "    \"\"\"\n",
    "    Evaluate the model and calculate accuracy, F1-score, and classwise accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Classwise metrics\n",
    "            for label, pred in zip(labels, preds):\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "                class_total[label] += 1\n",
    "\n",
    "    # Overall accuracy\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # F1-Score\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # Classwise accuracy\n",
    "    classwise_accuracy = [c / t if t > 0 else 0 for c, t in zip(class_correct, class_total)]\n",
    "\n",
    "    return accuracy, f1, classwise_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb1d957-0bdd-4af5-a151-7723c50c7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_with_tensorboard(\n",
    "    model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs, device, num_classes, writer\n",
    "):\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = train_correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        val_acc, val_f1, val_classwise_acc = evaluate_model_with_metrics(model, val_loader, device, num_classes)\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar(\"Loss/train\", train_loss / len(train_loader), epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "        writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "        writer.add_scalar(\"F1/val\", val_f1, epoch)\n",
    "\n",
    "        # Log classwise accuracy as individual scalars\n",
    "        for i, acc in enumerate(val_classwise_acc):\n",
    "            writer.add_scalar(f\"Classwise Accuracy/val_class_{i}\", acc, epoch)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"  Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"  Validation Accuracy: {val_acc:.4f}, Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    # Final evaluation on the test set\n",
    "    print(\"Final evaluation on the test set:\")\n",
    "    test_acc, test_f1, classwise_acc = evaluate_model_with_metrics(model, test_loader, device, num_classes)\n",
    "\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Test F1-Score: {test_f1:.4f}\")\n",
    "    print(f\"  Classwise Accuracy: {classwise_acc}\")\n",
    "\n",
    "    # Log test metrics to TensorBoard\n",
    "    writer.add_scalar(\"Accuracy/test\", test_acc, num_epochs)\n",
    "    writer.add_scalar(\"F1/test\", test_f1, num_epochs)\n",
    "    for i, acc in enumerate(classwise_acc):\n",
    "        writer.add_scalar(f\"Classwise Accuracy/test_class_{i}\", acc, num_epochs)\n",
    "\n",
    "    return test_acc, test_f1, classwise_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996ad758-5444-416e-b893-e14288610dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6c4531825846b423\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6c4531825846b423\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "592f4fca-b320-4a75-9fae-35280ae93902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model = model.to(device)\n",
    "    test_acc = evaluate_model(model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3babc9f3-4a16-4296-8d4f-a9c13971dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 9\n",
    "resnet18 = ResNet18(num_classes=num_classes).to(device)\n",
    "optimizer_sgd = torch.optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f503b01-7b01-4333-8f58-1086812d0caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet18 with SGD...\n",
      "Epoch [1/10]\n",
      "  Train Loss: 1.5923, Train Accuracy: 0.4212\n",
      "  Validation Accuracy: 0.3764, Validation F1-Score: 0.3336\n",
      "Epoch [2/10]\n",
      "  Train Loss: 1.3292, Train Accuracy: 0.5292\n",
      "  Validation Accuracy: 0.5028, Validation F1-Score: 0.4640\n",
      "Epoch [3/10]\n",
      "  Train Loss: 1.2135, Train Accuracy: 0.5514\n",
      "  Validation Accuracy: 0.5154, Validation F1-Score: 0.4943\n",
      "Epoch [4/10]\n",
      "  Train Loss: 1.1254, Train Accuracy: 0.5803\n",
      "  Validation Accuracy: 0.6011, Validation F1-Score: 0.5809\n",
      "Epoch [5/10]\n",
      "  Train Loss: 1.0264, Train Accuracy: 0.6302\n",
      "  Validation Accuracy: 0.6067, Validation F1-Score: 0.5978\n",
      "Epoch [6/10]\n",
      "  Train Loss: 1.0034, Train Accuracy: 0.6290\n",
      "  Validation Accuracy: 0.6503, Validation F1-Score: 0.6410\n",
      "Epoch [7/10]\n",
      "  Train Loss: 0.9552, Train Accuracy: 0.6584\n",
      "  Validation Accuracy: 0.6306, Validation F1-Score: 0.6304\n",
      "Epoch [8/10]\n",
      "  Train Loss: 0.9118, Train Accuracy: 0.6651\n",
      "  Validation Accuracy: 0.5688, Validation F1-Score: 0.5778\n",
      "Epoch [9/10]\n",
      "  Train Loss: 0.8640, Train Accuracy: 0.6810\n",
      "  Validation Accuracy: 0.6404, Validation F1-Score: 0.6312\n",
      "Epoch [10/10]\n",
      "  Train Loss: 0.8127, Train Accuracy: 0.7029\n",
      "  Validation Accuracy: 0.6896, Validation F1-Score: 0.6877\n",
      "Final evaluation on the test set:\n",
      "  Test Accuracy: 0.6793\n",
      "  Test F1-Score: 0.6767\n",
      "  Classwise Accuracy: [0.5753424657534246, 0.8909090909090909, 0.7903225806451613, 0.7217391304347827, 0.5161290322580645, 0.6486486486486487, 0.7445255474452555, 0.5, 0.6949152542372882]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ResNet18 with SGD...\")\n",
    "resnet_test_acc, resnet_test_f1, resnet_classwise_acc = train_and_evaluate_with_tensorboard(\n",
    "    resnet18, train_loader, val_loader, test_loader, optimizer_sgd, criterion,\n",
    "    num_epochs=10, device=device, num_classes=num_classes, writer=writer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a2f3cc4-2c84-4f66-a1b9-7a0771661ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16 with Adam...\n",
      "Epoch [1/10]\n",
      "  Train Loss: 6.5228, Train Accuracy: 0.2384\n",
      "  Validation Accuracy: 0.3638, Validation F1-Score: 0.3189\n",
      "Epoch [2/10]\n",
      "  Train Loss: 2.1899, Train Accuracy: 0.3349\n",
      "  Validation Accuracy: 0.3553, Validation F1-Score: 0.3289\n",
      "Epoch [3/10]\n",
      "  Train Loss: 2.1029, Train Accuracy: 0.3533\n",
      "  Validation Accuracy: 0.3975, Validation F1-Score: 0.3341\n",
      "Epoch [4/10]\n",
      "  Train Loss: 2.0136, Train Accuracy: 0.3695\n",
      "  Validation Accuracy: 0.4593, Validation F1-Score: 0.4253\n",
      "Epoch [5/10]\n",
      "  Train Loss: 1.9131, Train Accuracy: 0.3876\n",
      "  Validation Accuracy: 0.4747, Validation F1-Score: 0.4555\n",
      "Epoch [6/10]\n",
      "  Train Loss: 1.8547, Train Accuracy: 0.3996\n",
      "  Validation Accuracy: 0.4438, Validation F1-Score: 0.4199\n",
      "Epoch [7/10]\n",
      "  Train Loss: 1.8774, Train Accuracy: 0.3812\n",
      "  Validation Accuracy: 0.4326, Validation F1-Score: 0.4009\n",
      "Epoch [8/10]\n",
      "  Train Loss: 1.7730, Train Accuracy: 0.4146\n",
      "  Validation Accuracy: 0.4565, Validation F1-Score: 0.4346\n",
      "Epoch [9/10]\n",
      "  Train Loss: 1.7657, Train Accuracy: 0.4152\n",
      "  Validation Accuracy: 0.4424, Validation F1-Score: 0.4344\n",
      "Epoch [10/10]\n",
      "  Train Loss: 1.7997, Train Accuracy: 0.4089\n",
      "  Validation Accuracy: 0.4817, Validation F1-Score: 0.4618\n",
      "Final evaluation on the test set:\n",
      "  Test Accuracy: 0.4342\n",
      "  Test F1-Score: 0.4118\n",
      "  Classwise Accuracy: [0.23333333333333334, 0.4482758620689655, 0.625, 0.4251968503937008, 0.05714285714285714, 0.7727272727272727, 0.4, 0.32, 0.8148148148148148]\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16(num_classes=num_classes).to(device)\n",
    "optimizer_adam = torch.optim.Adam(vgg16.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training VGG16 with Adam...\")\n",
    "vgg_test_acc, vgg_test_f1, vgg_classwise_acc = train_and_evaluate_with_tensorboard(\n",
    "    vgg16, train_loader, val_loader, test_loader, optimizer_adam, criterion,\n",
    "    num_epochs=10, device=device, num_classes=num_classes, writer=writer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a26a3-7a8c-4582-b4bd-b73fbec1e656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
